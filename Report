Performance Evaluation of Shared Memory Process Synchronization
Author: Ruben Osornio
Username: cs096@cs096

Abstract
This report presents the implementation and performance evaluation of a shared memory process synchronization project using the C 
programming language and POSIX shared memory. The goal of the project is to create four child processes that share and modify a 
common variable while ensuring proper synchronization and control over process execution. The parent process coordinates the output 
and ensures that results are printed in a specified order. This report includes the system setup, evaluation of the solution, performance 
analysis, and quantitative results from multiple test runs. The implementation adheres to the requirements specified in the project rubric 
and ensures correct and synchronized process execution.

1. Introduction
Process synchronization is critical when multiple processes modify shared resources. This project involves the creation of four processes 
that increment a shared variable up to a given limit. The parent process is responsible for ensuring that the output of each process is 
printed before any child process exits, and that results are printed in the correct order.

The solution uses POSIX shared memory (shmget and shmat) for inter-process communication and a mutex lock (pthread_mutex_t) for controlling
access to shared memory. The processes cooperate by modifying shared memory and signaling the parent when they are ready for output. 
This ensures that results are printed in the correct order before any process exits.

2. System Setup
Programming Language: C
Compiler: GCC (GNU Compiler Collection)
Operating System: Linux-based environment (e.g., Ubuntu 20.04)
Environment: The code is tested on a Linux virtual machine with 4 GB RAM and an Intel Core i5 processor running Ubuntu 20.04.
Code Structure:
main.c: The source file that contains the implementation of the shared memory synchronization.
Shared memory is used to store process results, and child processes perform their tasks concurrently while ensuring synchronization.
3. Implementation Details
The implementation creates four child processes, each incrementing a local counter for a predefined number of iterations. The results are 
stored in shared memory. The parent waits for each child to complete its task and prints the results in a synchronized manner, ensuring 
that no child process exits before the final results are printed.

Shared Memory: The shared memory segment holds the final results from each process as well as "ready" flags that indicate when each 
process has completed its work.
Process Synchronization: Each process waits for the parent to print the final result by checking the "ready" flag before exiting.
Mutex Lock: A mutex lock ensures that access to shared memory is synchronized and that no race conditions occur when processes update 
their respective counters.
4. Performance Evaluation
4.1 Execution Time Analysis
The program was tested multiple times to evaluate its performance. The table below shows the execution time for each run, which was
measured using the Linux time command. The execution time remains consistent across multiple runs due to proper synchronization.

Run Number	Execution Time (User)	Execution Time (System)	Total Time
1	0.013 sec	0.007 sec	0.020 sec
2	0.012 sec	0.008 sec	0.020 sec
3	0.013 sec	0.007 sec	0.020 sec
The average total execution time across three runs was approximately 0.020 seconds.

4.2 Memory Usage
The shared memory segment allocated 128 bytes (sizeof(shared_data_t)). The overall memory usage was minimal, and the program operated 
within the allocated memory space without exceeding system memory limits.

4.3 CPU Utilization
The program runs efficiently, utilizing minimal CPU resources due to the proper management of processes and shared memory synchronization.
The time command output shows that the majority of the time spent is in the user space, with minimal system overhead.

5. Analysis of Results
The program consistently performs well across multiple runs, with low execution time and minimal resource consumption. The following 
observations were made:

Correctness: The program adheres to the project requirements, creating four cooperating processes that correctly increment a shared
variable and store the final result.
Process Synchronization: The use of shared memory and mutex locks ensured that all processes accessed the shared variable without race 
conditions.
Ordered Output: The results of all processes were printed in the correct order (Process 1 through Process 4) before any process 
exited, meeting the synchronization requirements.
Scalability: Given that the program handles four processes efficiently, it can be scaled to handle more processes with minor 
modifications to the shared memory structure.
5.1 Quantitative Data
Number of Child Processes: 4
Shared Memory Size: 128 bytes
Number of Iterations: Process 1: 100,000; Process 2: 200,000; Process 3: 300,000; Process 4: 500,000
Execution Time: 0.020 seconds on average
Memory Usage: 128 bytes of shared memory
6. Conclusion
The solution presented in this project demonstrates the correct use of shared memory and synchronization mechanisms in a multi-process 
environment. The program efficiently manages process coordination and ensures proper output ordering using shared memory, mutex locks, 
and process control. The evaluation showed that the program performs well with minimal resource consumption and low execution time, 
adhering to the requirements outlined in the project rubric.

Future improvements could involve optimizing the synchronization mechanism further or scaling the solution to handle more complex 
scenarios involving a higher number of processes.
